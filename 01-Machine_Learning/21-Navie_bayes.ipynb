{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navie Bayes Algorithm (NB)\n",
    "- simple but surprisinly powerful alogrithm for predictive modeling and machine learning.\n",
    "- based on bayes therom\n",
    "- particularly useful in the classification taks.\n",
    "- text classification tasks such spam filtering and sentiment analysis \n",
    "### Navie Bayes Alogrithm (NB)\n",
    "Navie bayes is a  probabilistic machine learning model that is used for classification tasks.\\\n",
    "it is based on the bayes therom which describe the probability of an event on the prior knowledge of conditions related to the event.\\\n",
    "The navie aspect's of algortim comes from the facts that features that used to predict the target variable and indepedent of each other.\n",
    "### Bayes Therom (BT)\n",
    "At it's core bayes therom provides a way to calculate the probability of an hypothesis based the prior knowledge.Mathmatically, it's expressed as \n",
    " P(A|B)= P(B|A)*P(A)/P(B)\\\n",
    " where:P(A|B) is the probability of hypothesis A given by the data B.\\\n",
    " P(A|B) is the probability of data B given that hypothesis A is correct.\\\n",
    " P(A) is the probability of hypothesis A begin ture (regardless of the given data B)\\\n",
    " P(B) is the probability of Data B (regardless of the hypothesis A)\n",
    " ## Types of Naive Bayes classifier \n",
    " ### 1. Gussian Navie Bayes:\n",
    " Used When features are contionus and normaly distributed\n",
    " ### 2. Multinominal Navie Bayes\n",
    " Often used for document classification. Where the features are the frequenices of the words or tokens in the documents.\n",
    " ### Bernouli Navie Bayes:\n",
    " Used when features are binary(0s and 1s)\n",
    "\n",
    " ## Application of Navie Bayes\n",
    " - Email spam filtering \n",
    " - Sentiment analysis\n",
    " - Docutment Categorization\n",
    " - Medical Diagonsis\n",
    " ## Advantages of Navie Bayes\n",
    " - **Simplicity**: They are straightforward to implement and understand \n",
    " - **Efficiency**: Require small amount of a training data to estimate the necessay parameters.\n",
    " - **Speed**: Very fast, making them suitable for real time predications.\n",
    " - **Good performance**: Often perform well in mutli-class predication\n",
    " ## Disadvantages of Navie Bayes:\n",
    " 1. **Feature Independence:**  The assumption is a independent features is the strong one and not applicable in some cases.\n",
    " 2. **Data Scarcity:** If the categorical data has category in testing data set, which model haven't seen in the traning data. The model wil assign the zero probability to it and will not be able to make prediction. This is often knows as **Zero Frequency**\n",
    " 3. **Highly Corelated features** The Model will not perform well when the feature are highly corelated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      0.92      0.96        12\n",
      "           2       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.96      0.97      0.96        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "Confusion Matrix:\n",
      " [[11  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  0  7]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.datasets import load_iris\n",
    "# split the data into x and y \n",
    "iris= load_iris()\n",
    "x = iris.data \n",
    "  \n",
    "y = iris.target\n",
    "# split the data into traning and testing data \n",
    "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.2,random_state=21)\n",
    "Gnb= GaussianNB()\n",
    "# fit the model \n",
    "Gnb.fit(x_train,y_train)\n",
    "# predict from the model\n",
    "y_pred= Gnb.predict(x_test)\n",
    "# Evaluate the Model\n",
    "print(\"Classification Report:\\n\", classification_report(y_test,y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      0.33      0.50        12\n",
      "           2       0.47      1.00      0.64         7\n",
      "\n",
      "    accuracy                           0.73        30\n",
      "   macro avg       0.82      0.78      0.71        30\n",
      "weighted avg       0.88      0.73      0.72        30\n",
      "\n",
      "Confusion Matrix:\n",
      " [[11  0  0]\n",
      " [ 0  4  8]\n",
      " [ 0  0  7]]\n"
     ]
    }
   ],
   "source": [
    "# Mulitnominal algorithm\n",
    "Mnb= MultinomialNB()\n",
    "Mnb.fit(x_train,y_train)\n",
    "y_pred=Mnb.predict(x_test)\n",
    "print(\"Classification Report\\n\",classification_report(y_test,y_pred))\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.00      0.00      0.00        12\n",
      "           2       0.23      1.00      0.38         7\n",
      "\n",
      "    accuracy                           0.23        30\n",
      "   macro avg       0.08      0.33      0.13        30\n",
      "weighted avg       0.05      0.23      0.09        30\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 0  0 11]\n",
      " [ 0  0 12]\n",
      " [ 0  0  7]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Basit\\miniconda3\\envs\\python_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Basit\\miniconda3\\envs\\python_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Basit\\miniconda3\\envs\\python_ml\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Bnb = BernoulliNB()\n",
    "Bnb.fit(x_train,y_train)\n",
    "y_pred = Bnb.predict(x_test)\n",
    "print(\"Classification Report\\n\",classification_report(y_test,y_pred))\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
