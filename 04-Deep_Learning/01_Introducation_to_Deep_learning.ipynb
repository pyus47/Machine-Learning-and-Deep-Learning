{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning:\n",
    "Deep Learning is the subfield of AI and Machine Learning.Deep learning which puts much emphasis on the learning successive layers meanningful representations.In Deep learning layered represntation of data are learned by using neural networks.\n",
    "## Neural Networks:\n",
    "Neural Networks is a series of algorithms that endeavors to recognize the underlying relationship in a set of data through a process that mimics the way that human brain operators.\n",
    "## Components of neural Networks:\n",
    "### 1. Nodes or Neurons\n",
    "Basics units of neural networks, analogous to human brain neurons, which process and transmit information.\n",
    "### 2. Layers: \n",
    "Neural Networks are composed of mutliple layers of nodes. Usally consist of input layer which receive input data. some hidden layers which process information and output layer which gives the output.\n",
    "### 3. Weights and Biases:\n",
    "Connections between neurons or nodes have weights, that adust as the learning proceeds, and neuron may have a bias term,both of with may determine the strength and direction of the influence one neuron has on another.\n",
    "### 4. Activation Function.\n",
    "Function that decides whether the nurons should be activated,influencing the network ability to learn complex representation of data.\n",
    "## Types of Neural Networks:\n",
    "### 1. Feedforward Neural Networks:  Complexity Simple\n",
    "Basic classification and regression tasks pattern recongnition.\n",
    "### 2. Convolutional Neural Networks: Complexity Moderate\n",
    "image recongintion, image analysis and video analysis, computer vision.\n",
    "### 3. Recurrent Neural Networks:\n",
    "sequence modelling, such as time series analysis,natural language processing, specch recogintion.\n",
    "### 4. LSTM Long-Short Term Memory Networks:\n",
    "Learning long term dependenices in sequence data, language modelling,text generation,machine learning.\n",
    "### 5. Radial Basis Functions:\n",
    "Function approximation, time series prediction,classification in high dimensional space.\n",
    "### 6. Self Organizing Maps\n",
    "Visualization of high dimensional data, dimensionality reducation and clustering.\n",
    "### 7. Deep Belief Networks: Complexity High\n",
    "image recoginition video recogintion, motion capture analysis.\n",
    "### 8. Generative Adversarial Networks:\n",
    "Generative new data samples (image text etc),artistic creation, image super resolution.\n",
    "### 9. AutoEncoders:\n",
    "Dimensionality reduction, noise reduction, feature learning, data generation.\n",
    "### 10. Modular Neural Networks:\n",
    "Tasks requrining the combination of different networks, such as complex pattern recogintion problems.\n",
    "### 11. Neural Turning Machines: Complexity Very High\n",
    "Enhancing neural networks with memory and attentin mechanisms,complex problem sloving tasks.\n",
    "### 12. Capsule neural networks:\n",
    "Improve the efficiency and  accuracy of neural networks in taks like image recognition and object dectection.\n",
    "\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
